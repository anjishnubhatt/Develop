{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf476b0e",
   "metadata": {},
   "source": [
    "# Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d60179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, ParameterGrid\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697eff15",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671fbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sales_data.csv')  # Replace 'sales_data.csv' with your actual file name or path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7731d17",
   "metadata": {},
   "source": [
    "# Standard Deviation calculation and normalising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2da0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant columns for anomaly detection (e.g., sales amount, store number, date)\n",
    "selected_columns = ['sales_amount', 'store_number', 'date']\n",
    "data = df[selected_columns]\n",
    "\n",
    "# Calculate the standard deviation of sales_amount for each store\n",
    "store_std = data.groupby('store_number')['sales_amount'].std().reset_index()\n",
    "store_std.rename(columns={'sales_amount': 'std_dev'}, inplace=True)\n",
    "\n",
    "# Normalize the sales_amount using the store's standard deviation\n",
    "data = pd.merge(data, store_std, on='store_number')\n",
    "data['sales_amount_normalized'] = (data['sales_amount'] - data['std_dev']) / data['std_dev']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33476ab5",
   "metadata": {},
   "source": [
    "# Loading the anomally algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c59b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize anomaly detection models\n",
    "isolation_forest = IsolationForest(contamination=0.05)\n",
    "local_outlier_factor = LocalOutlierFactor(contamination=0.05)\n",
    "one_class_svm = OneClassSVM(nu=0.05)\n",
    "robust_covariance = EllipticEnvelope(contamination=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd66fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize anomaly detection models\n",
    "isolation_forest = IsolationForest()\n",
    "local_outlier_factor = LocalOutlierFactor()\n",
    "one_class_svm = OneClassSVM()\n",
    "robust_covariance = EllipticEnvelope()\n",
    "\n",
    "# Define parameter grids for hyperparameter tuning\n",
    "param_grid_if = {'n_estimators': [100, 200, 300], 'contamination': [0.05, 0.1, 0.15]}\n",
    "param_grid_lof = {'n_neighbors': [5, 10, 15], 'contamination': [0.05, 0.1, 0.15]}\n",
    "param_grid_ocsvm = {'nu': [0.05, 0.1, 0.15]}\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "anomalous_dates_df = pd.DataFrame(columns=['store_number', 'date'])\n",
    "\n",
    "# Iterate over each store\n",
    "for store in data['store_number'].unique():\n",
    "    # Filter data for the current store\n",
    "    store_data = data[data['store_number'] == store]\n",
    "\n",
    "    # Check for infinity or large values and replace them with NaN\n",
    "    store_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    store_data.dropna(subset=['sales_amount_normalized'], inplace=True)\n",
    "\n",
    "    if store_data.empty:\n",
    "        continue\n",
    "\n",
    "    # Perform hyperparameter tuning using cross-validation for each model\n",
    "    best_score_if = -np.inf\n",
    "    best_params_if = None\n",
    "    for params in ParameterGrid(param_grid_if):\n",
    "        isolation_forest.set_params(**params)\n",
    "        isolation_forest.fit(store_data[['sales_amount_normalized']])  # Fit the model\n",
    "        scores = isolation_forest.decision_function(store_data[['sales_amount_normalized']])\n",
    "        mean_score = np.mean(scores)\n",
    "        if mean_score > best_score_if:\n",
    "            best_score_if = mean_score\n",
    "            best_params_if = params\n",
    "\n",
    "    best_score_lof = -np.inf\n",
    "    best_params_lof = None\n",
    "    for params in ParameterGrid(param_grid_lof):\n",
    "        local_outlier_factor.set_params(**params)\n",
    "        local_outlier_factor.fit(store_data[['sales_amount_normalized']])  # Fit the model\n",
    "        scores = -local_outlier_factor.negative_outlier_factor_\n",
    "        mean_score = np.mean(scores)\n",
    "        if mean_score > best_score_lof:\n",
    "            best_score_lof = mean_score\n",
    "            best_params_lof = params\n",
    "\n",
    "    best_score_ocsvm = -np.inf\n",
    "    best_params_ocsvm = None\n",
    "    for params in ParameterGrid(param_grid_ocsvm):\n",
    "        one_class_svm.set_params(**params)\n",
    "        one_class_svm.fit(store_data[['sales_amount_normalized']])  # Fit the model\n",
    "        scores = one_class_svm.decision_function(store_data[['sales_amount_normalized']])\n",
    "        mean_score = np.mean(scores)\n",
    "        if mean_score > best_score_ocsvm:\n",
    "            best_score_ocsvm = mean_score\n",
    "            best_params_ocsvm = params\n",
    "\n",
    "    # Fit the models to the store's normalized sales_amount data using the best parameters from cross-validation\n",
    "    isolation_forest.set_params(**best_params_if)\n",
    "    local_outlier_factor.set_params(**best_params_lof)\n",
    "    one_class_svm.set_params(**best_params_ocsvm)\n",
    "    isolation_forest.fit(store_data[['sales_amount_normalized']])\n",
    "    local_outlier_factor.fit(store_data[['sales_amount_normalized']])\n",
    "    one_class_svm.fit(store_data[['sales_amount_normalized']])\n",
    "    scores_rc = robust_covariance.fit(store_data[['sales_amount_normalized']]).decision_function(store_data[['sales_amount_normalized']])\n",
    "\n",
    "    # Predict the anomaly scores for each model\n",
    "    scores_if = isolation_forest.decision_function(store_data[['sales_amount_normalized']])\n",
    "    scores_lof = -local_outlier_factor.negative_outlier_factor_\n",
    "    scores_ocsvm = one_class_svm.decision_function(store_data[['sales_amount_normalized']])\n",
    "\n",
    "    # Ensemble anomaly scores by averaging\n",
    "    ensemble_scores = (scores_if + scores_lof + scores_ocsvm + scores_rc) / 4\n",
    "\n",
    "    # Add the anomalous dates to the dataframe\n",
    "    store_anomalous_dates = store_data[ensemble_scores < 0]['date']\n",
    "    anomalous_dates_df = anomalous_dates_df.append(pd.DataFrame({'store_number': store, 'date': store_anomalous_dates}))\n",
    "\n",
    "# Reset the index of the resulting dataframe\n",
    "anomalous_dates_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the dataframe with anomalous store numbers and dates\n",
    "print(anomalous_dates_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080493f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_dates_df.to_csv('anomalous_dates_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c15dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
